

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Fitting a straight line with non-symmetric (but Gaussian) uncertainties &mdash; fitting line sandbox 1.0 documentation</title>
  

  
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  
  

    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:'./',
        VERSION:'1.0',
        COLLAPSE_INDEX:false,
        FILE_SUFFIX:'.html',
        HAS_SOURCE:  true
      };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
    <script type="text/javascript">
        jQuery(function () {
            SphinxRtdTheme.StickyNav.enable();
        });
    </script>
  

  
    <link rel="top" title="fitting line sandbox 1.0 documentation" href="index.html"/> 

  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        <a href="index.html" class="fa fa-home"> fitting line sandbox</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
        
            <ul class="simple">
</ul>

        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">fitting line sandbox</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Fitting a straight line with non-symmetric (but Gaussian) uncertainties</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="_sources/README.txt" rel="nofollow"> View page source</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            
  <div class="section" id="fitting-a-straight-line-with-non-symmetric-but-gaussian-uncertainties">
<h1>Fitting a straight line with non-symmetric (but Gaussian) uncertainties<a class="headerlink" href="#fitting-a-straight-line-with-non-symmetric-but-gaussian-uncertainties" title="Permalink to this headline">¶</a></h1>
<p>This repository is an exercise I had with <strong>Iskren Georgiev</strong> when he was
looking at linear correlations between the stellar mass of galaxies and the
properties of their central nuclear star cluster.</p>
<p>The approach here is neither frequentist nor Bayesian but more like in between.
we explored how to quickly get fits through his data even when the uncertainties
were non-symmetric or upper limits.</p>
<div class="section" id="example-usage">
<h2>Example usage<a class="headerlink" href="#example-usage" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="definition-of-the-problem">
<h2>Definition of the problem<a class="headerlink" href="#definition-of-the-problem" title="Permalink to this headline">¶</a></h2>
<p>If we define the data set D with uncertainties E of <span class="math">\({d_k, e_k}\)</span>
independent observations and a model M predicting what the data should look
like. It comes through Bayes rule:</p>
<div class="math">
\[p(M | D, E) = 1 / Z  prod_k P(d_k| M, e_k) P(M)\]</div>
<p><span class="math">\(Z\)</span> is the evidence (normalization factor), <span class="math">\(P(d_k| M, e_k)\)</span> the
likelihood the the <span class="math">\(k\)</span>-th data point, and <span class="math">\(P(M)\)</span> the prior on the
model (or its parameters).</p>
</div>
<div class="section" id="non-symmetric-uncertainties">
<h2>Non-symmetric uncertainties<a class="headerlink" href="#non-symmetric-uncertainties" title="Permalink to this headline">¶</a></h2>
<p>This becomes trivial when uncertaintes are non-correlated by observing that it
corresponds to a skewed normal distribution. The latter can be very simply
defined by the closed form of a split normal distribution.</p>
<p>The split normal distribution arises from merging two opposite halves of two
probability density functions (PDFs) of normal distributions in their common
mode.</p>
<p>The PDF of the split normal distribution is given by:</p>
<div class="math">
\[\begin{split}f(x;\mu,\sigma_1,\sigma_2)= A \exp (- \frac {(x-\mu)^2}{2 \sigma_1^2})    if  x &lt; \mu
f(x;\mu,\sigma_1,\sigma_2)=   A \exp (- \frac {(x-\mu)^2}{2 \sigma_2^2})   otherwise\end{split}\]</div>
<p>where</p>
<div class="math">
\[A = \sqrt{2/\pi} (\sigma_1+\sigma_2)^{-1}.\]</div>
</div>
<div class="section" id="finite-data-sample">
<h2>Finite Data Sample<a class="headerlink" href="#finite-data-sample" title="Permalink to this headline">¶</a></h2>
<p>The finite data can be either discarded or accounted for by bootstrapping the
data. In other words, do multiple fits (with the above) to get one value per
resampling and combine them to get a PDF by integrating the different bootstrap
realizations.</p>
</div>
<div class="section" id="fitting-a-straight-line-to-data">
<h2>Fitting a straight line to data<a class="headerlink" href="#fitting-a-straight-line-to-data" title="Permalink to this headline">¶</a></h2>
<p>We define our model as follow:</p>
<div class="math">
\[y_{model}(x | \alpha, \beta) = \alpha \, x + \beta\]</div>
<p>I assume here that we have perfect &#8220;fake&#8221; data to work with, <span class="math">\((x_{data}, y_{data})\)</span>,
so that the MAP is actually trivial to get from the covariance of the sample:</p>
<div class="math">
\[C = Cov(x_{data}, y_{data})\]\[\alpha = \frac{C[1,0]}{C[0,0] ^ 2} = \frac{\rho_{x,y}\sigma_x\sigma_y}{\sigma_x ^ 2}\]\[\beta = \overline{y_{data}} - \alpha \, \overline{x_{data}}\]</div>
</div>
<div class="section" id="hat-trick-sampling-from-the-data">
<h2>Hat trick: sampling from the data<a class="headerlink" href="#hat-trick-sampling-from-the-data" title="Permalink to this headline">¶</a></h2>
<p>The approximation that we propose to do is to replace the data point <span class="math">\(d_k\)</span> by a
sampling of <span class="math">\(d_k\)</span> following the distribution given by <span class="math">\(e_k\)</span>. Here we suppose
normally distributed uncertainties.</p>
<p>it comes that either you can do</p>
<div class="math">
\[p(D | M) p(M) = prod_k \sum_j (P(d_{k,j}| M) \, P(M)),\]</div>
<p>when you use all the samples once, or</p>
<div class="math">
\[p(D | M) p(M) = \sum_j \prod_k (P(d_{k,j}| M) \, P(M)),\]</div>
<p>in the more proper way. The latter is marginalization of the posterior
distribution over noise, the former is faking by virtually expanding the data.</p>
<p>It is clear that both version will not lead to the same result, in particular
the final PDF of <span class="math">\(M\)</span>.</p>
<p>In this version of the script I consider the former trick implementation as it
also give me the possibility to do both with the same code. Simply increase the
bootstrapping number of realizations and put the sampling to 1 random sample.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">I actually ran both modes and get the same answer, which I don&#8217;t fully
understand.</p>
</div>
</div>
<div class="section" id="folding-in-the-intrinsic-dispersion">
<h2>Folding in the intrinsic dispersion<a class="headerlink" href="#folding-in-the-intrinsic-dispersion" title="Permalink to this headline">¶</a></h2>
<p>So far, everything we have done has implicitly assumed that there truly is a
narrow linear relationship between $x$ and $y$ (or there would be if
they were both measured with negligible uncertainties).</p>
<p>Since there are very few problems in science, especially in astrophysics, in
which a relationship between two observables is expected to be either narrow or
linear, we have to revise at least the narrow assumption.</p>
<p>The reasons for intrinsic scatter are not always obvious.  Commonly the
quantities being measured are produced or affected by a large number of
additional, unmeasured or unmeasurable quantities. The relation between
$x$ and $y$ is rarely exact, even in when observed by theoretically
perfect, noise-free observations.</p>
<p>Proper treatment of these problems gets into the complicated area of estimating
density given finite and noisy samples. However, we will limit ourselves to a
linear relation with some intrinsic scatter. As such, we will instead revise our
model that generates the data and infer the parameters of that model.</p>
<p>We introduce an intrinsic Gaussian variance $sigma^2$, orthogonal to the line. In
this case, the parameters of the relationship become $(alpha, beta, sigma^2)$</p>
<p>In this case, each data point <span class="math">\((x_i, y_i)\)</span> can be treated as being drawn
from a projected distribution function that is a convolution of the projected
uncertainty Gaussian.</p>
<div class="section" id="adapting-from-linear-algebra-projection">
<h3>Adapting from linear algebra projection<a class="headerlink" href="#adapting-from-linear-algebra-projection" title="Permalink to this headline">¶</a></h3>
<p>From a realization drawn from our data, we search for the only model that fits
to this perfect dataset. Hence the intrinsic dispersion perpendicular to the
linear model is also deterministically known.</p>
<p>Projection is a standard linear algebra technique.</p>
<p>A slope <span class="math">\(\alpha\)</span> can be described by a unit vector <span class="math">\(v\)</span> orthogonal to
the line representing the model:</p>
<div class="math">
\[v = \frac{1}{\sqrt{ 1 + m ^2}} . (-m, 1)^T\]</div>
<p>The orthogonal displacement <span class="math">\(\Delta_i\)</span> of each data point <span class="math">\(x_i,y_i\)</span>
from the line is given by:</p>
<div class="math">
\[\Delta_i = v^T . (d_i - \overline{d_i}),\]</div>
<p>The variance is then given by the usual unbiased estimator:</p>
<div class="math">
\[\sigma ^ 2 = \frac{1}{N-1}\sum_i \| \Delta_i \| ^ 2 = \frac{1}{N-1}\sum_i \| v^T . (d_i - \overline{d_i}) \| ^ 2\]</div>
</div>
</div>
</div>


          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015, M. Fouesneau and I. Georgiev.
    </p>
  </div>

  <a href="https://github.com/snide/sphinx_rtd_theme">Sphinx theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>
</footer>
        </div>
      </div>

    </section>

  </div>
  

</body>
</html>